{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost w/random search  optimization\n",
    "\n",
    "Swapping to XGBoost as my classifier-of-choice.\n",
    "\n",
    "Will use random search in order to optimize. \n",
    "\n",
    "May use F1-macro score to account for the class imbalances (approx. 2% anomalous examples).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'dynomics'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-0a18ea325866>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdatetime\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mdynomics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolors\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLogNorm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'dynomics'"
     ]
    }
   ],
   "source": [
    "# Load up the requisite libraries and submodules.\n",
    "import copy\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import time\n",
    "import xgboost as xgb\n",
    "\n",
    "from datetime import datetime\n",
    "from dynomics import models\n",
    "from matplotlib.colors import LogNorm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Define file locations.\n",
    "DATA_DIR = \"../data/multiclass/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load up the station IDs. Some of the Accl\n",
    "station_filenames_list = [\n",
    "    filename for filename in os.listdir(path=DATA_DIR)\n",
    "    if (filename[-7:]==\".pickle\") and (\"53155\" not in filename)\n",
    "]\n",
    "\n",
    "# List of \n",
    "stations_id_list = list(\n",
    "    set(\n",
    "        fname.split(\"_\")[2].split(\".\")[0] for fname in station_filenames_list\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle5 as pickle\n",
    "\n",
    "# with open(DATA_DIR+\"mc_features_03054.pickle\", \"rb\") as fh:\n",
    "#     data = pickle.load(fh)\n",
    "\n",
    "# data.to_pickle(\"test.pickle\", protocol=2)\n",
    "\n",
    "# df = pd.read_pickle(\"test.pickle\")\n",
    "\n",
    "# df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load features and targets into features and targets dictionaries, indexed\n",
    "# by station ID number.\n",
    "template_dict = {\n",
    "    station_id : None\n",
    "    for station_id in stations_id_list\n",
    "    if station_id != \"53155\"     # Station 53155's sensor data had data missing for at least one sensor\n",
    "                               # at literally every time point, so my data preprocessing eliminated it. \n",
    "}\n",
    "features_dict,targets_dict = copy.deepcopy(template_dict), copy.deepcopy(template_dict)\n",
    "del(template_dict)\n",
    "\n",
    "for fname in station_filenames_list:\n",
    "    station_id = fname.split(\"_\")[2].split(\".\")[0]\n",
    "    if station_id=='53155':\n",
    "        continue\n",
    "    elif \"features\" in fname:\n",
    "        features_dict[station_id] = pd.read_pickle(\n",
    "            DATA_DIR+fname,\n",
    "        )\n",
    "    elif \"targets\" in fname:\n",
    "        targets_dict[station_id] = pd.read_pickle(\n",
    "            DATA_DIR+fname,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_stations_list = [\n",
    "    station_id for station_id in features_dict.keys()\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Got the following station ID info from this URL:\n",
    "# https://mesonet.agron.iastate.edu/sites/site.php?station=23906&network=USCRN\n",
    "port_aransas_stat_id = \"23906\"\n",
    "feats_df_port_aransas = features_dict[port_aransas_stat_id]\n",
    "targs_df_port_aransas = targets_dict[port_aransas_stat_id]\n",
    "\n",
    "# Got the following date-exclusion idea from here:\n",
    "# https://stackoverflow.com/questions/55680603/pandas-filter-on-datetimeindex-by-excluding-date-range\n",
    "exclusion_dates = pd.date_range(start=\"2019-08-01\", end=\"2019-09-01\")\n",
    "\n",
    "features_dict[port_aransas_stat_id] = feats_df_port_aransas.loc[~feats_df_port_aransas.index.isin(exclusion_dates)]\n",
    "\n",
    "targets_dict[port_aransas_stat_id] = targs_df_port_aransas.loc[~targs_df_port_aransas.index.isin(exclusion_dates)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define ML functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_mkdirs(*paths):\n",
    "    for path in paths:\n",
    "        if not os.path.isdir(path):\n",
    "            os.makedirs(path)\n",
    "    return\n",
    "\n",
    "\n",
    "def confusion_score_model(\n",
    "    classer,\n",
    "    feature_frame,\n",
    "    target_frame,\n",
    "    cv_splits=None,\n",
    "    **fitting_kwargs\n",
    "):\n",
    "    ''' Construct the training and testing confusion matrixes for classer on\n",
    "        data\n",
    "        Input:\n",
    "            classer : sklearn.Estimator\n",
    "                a classifiers to train and score\n",
    "            feature_frame : DataFrame\n",
    "                A dataframe representing the features extracted from a set of\n",
    "                expeirments.\n",
    "            target_frame : DataFrame\n",
    "                a 1d representation of induction state at each time point in\n",
    "                feature_frame\n",
    "            cv_splits : [([],[])]\n",
    "                A list of (train,test) splits which should be used for cross\n",
    "                validation\n",
    "        Return: (pandas.DataFrame, pandas.DataFrame)\n",
    "            A tuple containing a DataFrame representing the confusion matrix\n",
    "            during cross validation and a DataFrame representing the\n",
    "            confusion matrix during training. i.e. (test_scores, train_scores)\n",
    "    '''\n",
    "    # Create variables to store conf matrix values during cross validation\n",
    "    unique_labels = target_frame.iloc[:, 0].unique()\n",
    "    num_labels = len(unique_labels)\n",
    "    test_mat = np.zeros((num_labels, num_labels))\n",
    "    train_mat = np.zeros((num_labels, num_labels))\n",
    "    # perform cross validation\n",
    "    for split_idx, (train, test) in enumerate(cv_splits):\n",
    "        print(\"##################################################\")\n",
    "        print(\"         ###### Processing \"+str(split_idx+1)+\" of \"+str(len(cv_splits))+\" ######\")\n",
    "        print(\"            \" + time.ctime())\n",
    "        print(\"##################################################\")\n",
    "        # get train and test splits\n",
    "        train_X = feature_frame.values[train]\n",
    "        train_y = target_frame.values.ravel()[train]\n",
    "        test_X = feature_frame.values[test]\n",
    "        test_y = target_frame.values.ravel()[test]\n",
    "        \n",
    "        # fit training data\n",
    "        classer.fit(\n",
    "            train_X, train_y, \n",
    "            eval_set=[(test_X, test_y)], \n",
    "            verbose=False,\n",
    "            **fitting_kwargs\n",
    "        )\n",
    "        \n",
    "        # Predict for training data and update confusion matrix\n",
    "        train_p = classer.predict(train_X)\n",
    "        temp = models.confusion_matrix(train_y, train_p, labels=unique_labels)\n",
    "        train_mat += temp / temp.sum().sum() / len(cv_splits)\n",
    "        # Predict for testing data and update confusion matrix\n",
    "        test_p = classer.predict(test_X)\n",
    "        temp = models.confusion_matrix(test_y, test_p, labels=unique_labels)\n",
    "        test_mat += temp / temp.sum().sum() / len(cv_splits)\n",
    "    # define helper to handle converting matrixes to dataframes\n",
    "    def to_frame(mat):\n",
    "        mat = pd.DataFrame(data=mat, index=unique_labels, columns=unique_labels)\n",
    "        mat.loc[:, 'sum'] = mat.sum(axis=1)\n",
    "        mat.loc['sum', :] = mat.sum(axis=0)\n",
    "        mat.index.name='True Label'\n",
    "        mat.columns.name='Predicted Label'\n",
    "        return mat\n",
    "    # convert matrixes to dataframes and return\n",
    "    return (to_frame(train_mat), to_frame(test_mat))\n",
    "\n",
    "def fix_conf_mat_labels(conf_mat):\n",
    "    # Format metal names so as to remove the remnants of tuple-formatting,\n",
    "    # which is an artifact of the MySQL database and its concentration \n",
    "    # specifications.\n",
    "    new_confusion_matrix_labels = [\n",
    "        label.split(\"'\")[1] \n",
    "        if \"'\" in label else label\n",
    "        for label in conf_mat.index.values\n",
    "    ]\n",
    "    conf_mat.index = new_confusion_matrix_labels\n",
    "    conf_mat.columns = new_confusion_matrix_labels\n",
    "    return conf_mat\n",
    "\n",
    "\n",
    "def plot_confusion_matrix(\n",
    "        cm_df,\n",
    "        title=None,\n",
    "        cmap=plt.cm.Blues,\n",
    "        fontsize=12,\n",
    "        fontcolor=None,\n",
    "        num_round=4,\n",
    "        plot_top=0.88,\n",
    "        cbar_ticks=None,\n",
    "        cbar_min_divisor=2,\n",
    "        figsize=None\n",
    "):\n",
    "    \"\"\"\n",
    "    Create and return a matplotlib figure representing a confusion matrix.\n",
    "\n",
    "    Input:\n",
    "        cm_df : pandas.DataFrame\n",
    "            a pandas dataframe representing a confusion matrix\n",
    "        title : str\n",
    "            a plot title\n",
    "        cmap : color map\n",
    "            some pyplot colormap to use in plotting\n",
    "        fontsize : int\n",
    "            how large the text in each posititon of the matrix should be\n",
    "        fontcolor : str\n",
    "            the color that the text in each position of the matrix\n",
    "    Return: pyplot.figure\n",
    "        a figure object representing the plot\n",
    "\"\"\"\n",
    "\n",
    "    # Set figure title.\n",
    "    if title is None:\n",
    "        title = 'Confusion matrix'\n",
    "\n",
    "    # Set figure fontcolor.\n",
    "    if fontcolor is None:\n",
    "        fontcolor = \"black\"\n",
    "    \n",
    "    if figsize is None:\n",
    "        figsize = (14, 10)\n",
    "\n",
    "    conf_mat = cm_df.values\n",
    "    conf_mat_nozeros = cm_df.copy()\n",
    "    #     conf_mat_nozeros['Sum'] = 0\n",
    "    #     conf_mat_nozeros.loc['Sum'] = 0\n",
    "    conf_mat_nozeros = conf_mat_nozeros.values\n",
    "\n",
    "    # Get class names.\n",
    "    classes = cm_df.index\n",
    "\n",
    "    # Set color bar ticks and format their labels.\n",
    "    if cbar_ticks is None:\n",
    "        cbar_ticks = [0.001, 0.01, 0.1, 0.2, 0.4, 0.8, 1.0]\n",
    "    cbar_tick_labels = [str(label) for label in cbar_ticks]\n",
    "\n",
    "    # Set color bar minimum and maximum.\n",
    "    cbar_min = np.min(\n",
    "        [i for i in cm_df.values.ravel() if i > 0]) / cbar_min_divisor\n",
    "    cbar_max = np.max([i for i in cm_df.values.ravel() if i < 1])\n",
    "\n",
    "    # Eliminate actual zeros from plotting data.\n",
    "    for i, row in enumerate(conf_mat):\n",
    "        for j, col in enumerate(row):\n",
    "            if col < cbar_min:\n",
    "                conf_mat_nozeros[i, j] = cbar_min\n",
    "\n",
    "    # Initialize figure and axes objects and plot colored cells.\n",
    "    fig, ax = plt.subplots(\n",
    "        1,\n",
    "        1,\n",
    "        figsize=figsize\n",
    "    )\n",
    "    cax = ax.imshow(\n",
    "        conf_mat_nozeros,\n",
    "        interpolation='nearest',\n",
    "        cmap=cmap,\n",
    "        norm=LogNorm(vmin=cbar_min, vmax=cbar_max)\n",
    "    )\n",
    "\n",
    "    # Add color bar, figure title, labels, and axis ticks.\n",
    "    cbar = fig.colorbar(cax, ax=ax, ticks=cbar_ticks)\n",
    "    cbar.ax.set_yticklabels(cbar_tick_labels)\n",
    "    fig.suptitle(\n",
    "        title,\n",
    "        **{'x': 0.53, 'y': 0.97}\n",
    "    )\n",
    "    ax.set_ylabel('True label')\n",
    "    ax.set_xlabel('Predicted label')\n",
    "    ticks = list(range(len(classes)))\n",
    "    plt.xticks(ticks, classes, rotation=45)\n",
    "    plt.yticks(ticks, classes)\n",
    "    ax.tick_params(axis=u'both', which=u'both', length=0)\n",
    "\n",
    "    # Add numerical values to the matrix's cells.\n",
    "    for i in range(conf_mat.shape[0]):\n",
    "        for j in range(conf_mat.shape[1]):\n",
    "            ax.text(\n",
    "                j,\n",
    "                i,\n",
    "                # conf_mat[i, j],\n",
    "                '{results:.{digits}f}'.format(\n",
    "                    results=conf_mat[i, j],\n",
    "                    digits=num_round\n",
    "                    ),\n",
    "                horizontalalignment=\"center\",\n",
    "                color=fontcolor,\n",
    "                fontsize=fontsize\n",
    "            )\n",
    "\n",
    "    # Format final image for saving.\n",
    "    plt.tight_layout()\n",
    "    plt.subplots_adjust(top=plot_top)\n",
    "\n",
    "    return fig, ax\n",
    "\n",
    "\n",
    "# def save_kwargs(kwargs_dict, kwargs_dict_name, data_save_dir):\n",
    "#     with open(data_save_dir+kwargs_dict_name+\".txt\", \"w\") as output_file:\n",
    "#         output_file.write(json.dumps(kwargs_dict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concatenate anomaly data for ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_feats_dict = {\n",
    "    stat_id : None\n",
    "    for stat_id in final_stations_list\n",
    "    if features_dict[stat_id].shape[1]==15\n",
    "}\n",
    "for stat_id in final_stations_list:\n",
    "    \n",
    "    df_to_scale = copy.deepcopy(features_dict[stat_id]).drop(columns=[\"p_official\", \"t_official\"])\n",
    "    \n",
    "    if df_to_scale.shape[1]==15:\n",
    "#         df_to_scale[(df_to_scale == -99999)] = pd.NA\n",
    "#         df_to_scale = df_to_scale.interpolate(method=\"time\", axis=0)\n",
    "#         df_to_scale = df_to_scale.fillna(method=\"bfill\", axis=0)\n",
    "        scaler = StandardScaler(with_mean=True)\n",
    "        feats_scaled_array = scaler.fit_transform(df_to_scale)\n",
    "#         if np.isnan(feats_scaled_array).sum() == 0:\n",
    "        scaled_feats_dict[stat_id] = copy.deepcopy(feats_scaled_array)\n",
    "    \n",
    "    else:\n",
    "        continue\n",
    "\n",
    "t = [stat_tuple[1] for stat_tuple in scaled_feats_dict.items()]\n",
    "scaled_feats_array = np.concatenate(t, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for stat_id in final_stations_list:\n",
    "    \n",
    "    df_to_scale = copy.deepcopy(features_dict[stat_id]).drop(columns=[\"p_official\", \"t_official\"])\n",
    "    \n",
    "    if df_to_scale.shape[1]==15:\n",
    "#         df_to_scale[(df_to_scale == -99999)] = pd.NA\n",
    "#         df_to_scale = df_to_scale.interpolate(method=\"time\", axis=0)\n",
    "#         df_to_scale = df_to_scale.fillna(method=\"bfill\", axis=0)\n",
    "        scaler = StandardScaler(with_mean=True)\n",
    "        feats_scaled_array = scaler.fit_transform(df_to_scale)\n",
    "        feats_scaled_df = pd.DataFrame(data=feats_scaled_array, index=df_to_scale.index, columns=df_to_scale.columns)\n",
    "#         if np.isnan(feats_scaled_array).sum() == 0:\n",
    "        scaled_feats_dict[stat_id] = copy.deepcopy(feats_scaled_df)\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "final_station_ids_list = [stat_id for stat_id in scaled_feats_dict.keys()]        \n",
    "\n",
    "features_dfs_list = [scaled_feats_dict[station_id] for station_id in final_station_ids_list]\n",
    "targets_dfs_list = [targets_dict[station_id] for station_id in final_station_ids_list]\n",
    "\n",
    "scaled_feats_df = pd.concat(features_dfs_list, axis=0)\n",
    "targs_df = pd.concat(targets_dfs_list, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_scaledfeats_targs_df = pd.concat([scaled_feats_df,targs_df], axis=1)\n",
    "\n",
    "# This takes a COUPLE MINUTES TO RUN. So, only re-run if necessary!!\n",
    "# # combined_scaledfeats_targs_df.to_csv(\"../data/combined_scaledfeats_targs_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(627937, 16)\n"
     ]
    }
   ],
   "source": [
    "print(combined_scaledfeats_targs_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_scaledfeats_targs_NONAN_df = combined_scaledfeats_targs_df.dropna(how=\"any\", axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-isolate the targets and then combine them into a 1-D pd.series. \n",
    "# Whenever a row has at least one anomaly, then we will collapse that row's \n",
    "# values to a single value of 1. Rows with no anomalies shall be labeled as 0.\n",
    "ml_targs_df = combined_scaledfeats_targs_NONAN_df.iloc[:, 15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-isolate the ML-ready features.\n",
    "ml_feats_df = combined_scaledfeats_targs_NONAN_df.iloc[:, :15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate the percentage of the ML-ready data that are anomalies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.32% of the data are anomalies.\n"
     ]
    }
   ],
   "source": [
    "percentage_anomalies = np.round(100 * (ml_targs_df != \"\").sum()/ml_targs_df.shape[0], 2 )\n",
    "\n",
    "print(f\"{percentage_anomalies}% of the data are anomalies.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Makeup by class\n",
      "###############\n",
      "normal: 97.68 %\n",
      "spike: 0.52 %\n",
      "noise: 1.8 %\n"
     ]
    }
   ],
   "source": [
    "print(\"Makeup by class\")\n",
    "print(\"###############\")\n",
    "for label in ml_targs_df.unique():\n",
    "    num_labels = (ml_targs_df == label).sum()\n",
    "    if label==\"\":\n",
    "        label=\"normal\"\n",
    "    print(label+\":\", np.round(100*num_labels/ml_targs_df.shape[0],2),\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform random search to optimize XGBoost classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "# [np.round(n, 0) for n in np.logspace(0.5, 3.1, num=7)]\n",
    "\n",
    "# [np.round(n, 0) for n in np.geomspace(20, 1500, num=6)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Jun  1 16:25:53 2021\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ggraham/miniconda3/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ggraham/miniconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/Users/ggraham/miniconda3/lib/python3.8/site-packages/xgboost/data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END gamma=0.1, learning_rate=0.8, max_depth=15, min_child_weight=9, n_estimators=20; total time=  28.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ggraham/miniconda3/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ggraham/miniconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/Users/ggraham/miniconda3/lib/python3.8/site-packages/xgboost/data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END gamma=0.1, learning_rate=0.8, max_depth=15, min_child_weight=9, n_estimators=20; total time=  29.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ggraham/miniconda3/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ggraham/miniconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/Users/ggraham/miniconda3/lib/python3.8/site-packages/xgboost/data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END gamma=0.1, learning_rate=0.8, max_depth=15, min_child_weight=9, n_estimators=20; total time=  29.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ggraham/miniconda3/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ggraham/miniconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/Users/ggraham/miniconda3/lib/python3.8/site-packages/xgboost/data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END gamma=0.0, learning_rate=0.8, max_depth=15, min_child_weight=5, n_estimators=457; total time= 7.3min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ggraham/miniconda3/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ggraham/miniconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/Users/ggraham/miniconda3/lib/python3.8/site-packages/xgboost/data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END gamma=0.0, learning_rate=0.8, max_depth=15, min_child_weight=5, n_estimators=457; total time= 6.5min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ggraham/miniconda3/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ggraham/miniconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/Users/ggraham/miniconda3/lib/python3.8/site-packages/xgboost/data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END gamma=0.0, learning_rate=0.8, max_depth=15, min_child_weight=5, n_estimators=457; total time= 6.8min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ggraham/miniconda3/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ggraham/miniconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/Users/ggraham/miniconda3/lib/python3.8/site-packages/xgboost/data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END gamma=0.5, learning_rate=0.4, max_depth=7, min_child_weight=9, n_estimators=44; total time=  39.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ggraham/miniconda3/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ggraham/miniconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/Users/ggraham/miniconda3/lib/python3.8/site-packages/xgboost/data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END gamma=0.5, learning_rate=0.4, max_depth=7, min_child_weight=9, n_estimators=44; total time=  39.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ggraham/miniconda3/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ggraham/miniconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/Users/ggraham/miniconda3/lib/python3.8/site-packages/xgboost/data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END gamma=0.5, learning_rate=0.4, max_depth=7, min_child_weight=9, n_estimators=44; total time=  42.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ggraham/miniconda3/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ggraham/miniconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/Users/ggraham/miniconda3/lib/python3.8/site-packages/xgboost/data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END gamma=0.3, learning_rate=0.8, max_depth=15, min_child_weight=5, n_estimators=20; total time=  40.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ggraham/miniconda3/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ggraham/miniconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/Users/ggraham/miniconda3/lib/python3.8/site-packages/xgboost/data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END gamma=0.3, learning_rate=0.8, max_depth=15, min_child_weight=5, n_estimators=20; total time=  36.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ggraham/miniconda3/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ggraham/miniconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/Users/ggraham/miniconda3/lib/python3.8/site-packages/xgboost/data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END gamma=0.3, learning_rate=0.8, max_depth=15, min_child_weight=5, n_estimators=20; total time=  36.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ggraham/miniconda3/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ggraham/miniconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/Users/ggraham/miniconda3/lib/python3.8/site-packages/xgboost/data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END gamma=0.5, learning_rate=0.1, max_depth=9, min_child_weight=7, n_estimators=44; total time=  53.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ggraham/miniconda3/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ggraham/miniconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/Users/ggraham/miniconda3/lib/python3.8/site-packages/xgboost/data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END gamma=0.5, learning_rate=0.1, max_depth=9, min_child_weight=7, n_estimators=44; total time=  53.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ggraham/miniconda3/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ggraham/miniconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/Users/ggraham/miniconda3/lib/python3.8/site-packages/xgboost/data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END gamma=0.5, learning_rate=0.1, max_depth=9, min_child_weight=7, n_estimators=44; total time=  50.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ggraham/miniconda3/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ggraham/miniconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/Users/ggraham/miniconda3/lib/python3.8/site-packages/xgboost/data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END gamma=0.3, learning_rate=0.4, max_depth=9, min_child_weight=9, n_estimators=209; total time= 3.5min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ggraham/miniconda3/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ggraham/miniconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/Users/ggraham/miniconda3/lib/python3.8/site-packages/xgboost/data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END gamma=0.3, learning_rate=0.4, max_depth=9, min_child_weight=9, n_estimators=209; total time= 3.2min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ggraham/miniconda3/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ggraham/miniconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/Users/ggraham/miniconda3/lib/python3.8/site-packages/xgboost/data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END gamma=0.3, learning_rate=0.4, max_depth=9, min_child_weight=9, n_estimators=209; total time= 3.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ggraham/miniconda3/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ggraham/miniconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/Users/ggraham/miniconda3/lib/python3.8/site-packages/xgboost/data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END gamma=0.3, learning_rate=0.1, max_depth=13, min_child_weight=5, n_estimators=44; total time= 1.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ggraham/miniconda3/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ggraham/miniconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/Users/ggraham/miniconda3/lib/python3.8/site-packages/xgboost/data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END gamma=0.3, learning_rate=0.1, max_depth=13, min_child_weight=5, n_estimators=44; total time= 1.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ggraham/miniconda3/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ggraham/miniconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/Users/ggraham/miniconda3/lib/python3.8/site-packages/xgboost/data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END gamma=0.3, learning_rate=0.1, max_depth=13, min_child_weight=5, n_estimators=44; total time= 1.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ggraham/miniconda3/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ggraham/miniconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/Users/ggraham/miniconda3/lib/python3.8/site-packages/xgboost/data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END gamma=0.3, learning_rate=0.4, max_depth=13, min_child_weight=11, n_estimators=457; total time= 8.4min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ggraham/miniconda3/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ggraham/miniconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/Users/ggraham/miniconda3/lib/python3.8/site-packages/xgboost/data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END gamma=0.3, learning_rate=0.4, max_depth=13, min_child_weight=11, n_estimators=457; total time= 9.2min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ggraham/miniconda3/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ggraham/miniconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/Users/ggraham/miniconda3/lib/python3.8/site-packages/xgboost/data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END gamma=0.3, learning_rate=0.4, max_depth=13, min_child_weight=11, n_estimators=457; total time= 8.9min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ggraham/miniconda3/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ggraham/miniconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/Users/ggraham/miniconda3/lib/python3.8/site-packages/xgboost/data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END gamma=0.4, learning_rate=0.4, max_depth=9, min_child_weight=7, n_estimators=1000; total time=15.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ggraham/miniconda3/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ggraham/miniconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/Users/ggraham/miniconda3/lib/python3.8/site-packages/xgboost/data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END gamma=0.4, learning_rate=0.4, max_depth=9, min_child_weight=7, n_estimators=1000; total time=15.4min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ggraham/miniconda3/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ggraham/miniconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/Users/ggraham/miniconda3/lib/python3.8/site-packages/xgboost/data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END gamma=0.4, learning_rate=0.4, max_depth=9, min_child_weight=7, n_estimators=1000; total time=15.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ggraham/miniconda3/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ggraham/miniconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/Users/ggraham/miniconda3/lib/python3.8/site-packages/xgboost/data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END gamma=0.0, learning_rate=0.4, max_depth=7, min_child_weight=11, n_estimators=457; total time= 5.6min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ggraham/miniconda3/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ggraham/miniconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/Users/ggraham/miniconda3/lib/python3.8/site-packages/xgboost/data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END gamma=0.0, learning_rate=0.4, max_depth=7, min_child_weight=11, n_estimators=457; total time= 5.6min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ggraham/miniconda3/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ggraham/miniconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/Users/ggraham/miniconda3/lib/python3.8/site-packages/xgboost/data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END gamma=0.0, learning_rate=0.4, max_depth=7, min_child_weight=11, n_estimators=457; total time= 5.6min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ggraham/miniconda3/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ggraham/miniconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=[(array([495844, 303147, 181224, ..., 505178, 555009,  54054]),\n",
       "                        array([443899,  38632,  94210, ...,   3572,  94390, 282697])),\n",
       "                       (array([286236,  87627,  15516, ..., 329050, 404564, 163884]),\n",
       "                        array([289498, 252073, 577306, ...,  59136, 515473,  34690])),\n",
       "                       (array([283548, 480815, 299186, ..., 597082, 145449, 383697]),\n",
       "                        array([480029, 619993, 469435, ..., 487961, 501114,  15531]))],\n",
       "                   e...\n",
       "                                           random_state=None, reg_alpha=None,\n",
       "                                           reg_lambda=None,\n",
       "                                           scale_pos_weight=None,\n",
       "                                           subsample=None, tree_method=None,\n",
       "                                           validate_parameters=None,\n",
       "                                           verbosity=None),\n",
       "                   param_distributions={'gamma': [0.0, 0.1, 0.2, 0.3, 0.4, 0.5],\n",
       "                                        'learning_rate': [0.1, 0.4, 0.8],\n",
       "                                        'max_depth': range(7, 16, 2),\n",
       "                                        'min_child_weight': range(5, 13, 2),\n",
       "                                        'n_estimators': [20, 44, 96, 209, 457,\n",
       "                                                         1000]},\n",
       "                   scoring='f1_macro', verbose=2)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define caching directories.\n",
    "master_dir = \"20210506_XGB_MC_random_search/\"\n",
    "plot_dir = \"plots/\" + master_dir\n",
    "data_save_dir = \"data/\" + master_dir\n",
    "check_mkdirs(plot_dir, data_save_dir)\n",
    "\n",
    "classer_init_kwargs = {\n",
    "    \"n_jobs\":-1,\n",
    "    \"objective\":\"multi:softmax\",\n",
    "}\n",
    "\n",
    "fitting_kwargs = {\n",
    "#     \"early_stopping_rounds\":50,\n",
    "    \"eval_metric\":\"merror\",\n",
    "    \"verbose\":False,\n",
    "}\n",
    "\n",
    "param_test_00 = {\n",
    "    \"n_estimators\": [int(np.round(n, 0)) for n in np.geomspace(20, 1000, num=6)], \n",
    "    \"learning_rate\":[0.1, 0.4, 0.8],\n",
    "    'max_depth':range(7, 16,2),\n",
    "    'min_child_weight':range(5, 13, 2),\n",
    "    'gamma':[i/10.0 for i in range(0, 6)]\n",
    "}\n",
    "\n",
    "features = combined_scaledfeats_targs_NONAN_df.iloc[:,0:15]\n",
    "\n",
    "targets = combined_scaledfeats_targs_NONAN_df[\"TAGS\"].to_frame()\n",
    "\n",
    "cv = StratifiedShuffleSplit(n_splits=3, random_state=7)\n",
    "\n",
    "splits = [split_indices for split_indices in cv.split(features.values, targets.values)]\n",
    "\n",
    "print(time.ctime())\n",
    "\n",
    "classer = xgb.XGBClassifier(**classer_init_kwargs)\n",
    "gridsearch_00 = sklearn.model_selection.RandomizedSearchCV(\n",
    "    estimator=classer,\n",
    "    n_iter=10,\n",
    "    param_distributions=param_test_00,\n",
    "    scoring=\"f1_macro\",\n",
    "    cv=splits,\n",
    "    verbose=2,\n",
    ")\n",
    "\n",
    "gridsearch_00.fit(features, targets, **fitting_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data/20210506_XGB_MC_random_search/gridsearch_00.pickle']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(gridsearch_00, \"data/\" + master_dir + \"gridsearch_00.pickle\")\n",
    "\n",
    "# print(time.ctime())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 1000,\n",
       " 'min_child_weight': 7,\n",
       " 'max_depth': 9,\n",
       " 'learning_rate': 0.4,\n",
       " 'gamma': 0.4}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gridsearch_00.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9848578050474863"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gridsearch_00.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate confusion matrices using best estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##################################################\n",
      "         ###### Processing 1 of 10 ######\n",
      "            Tue Jun  1 19:17:16 2021\n",
      "##################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ggraham/miniconda3/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:17:18] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'models' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-0b500a51e668>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Calculate the training and testing confusion matrices with the classifier and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m train_df, test_df = confusion_score_model(\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mgridsearch_00\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-f78afc40dc1d>\u001b[0m in \u001b[0;36mconfusion_score_model\u001b[0;34m(classer, feature_frame, target_frame, cv_splits, **fitting_kwargs)\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0;31m# Predict for training data and update confusion matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0mtrain_p\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclasser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0mtemp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_p\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0munique_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m         \u001b[0mtrain_mat\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtemp\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mtemp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv_splits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0;31m# Predict for testing data and update confusion matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'models' is not defined"
     ]
    }
   ],
   "source": [
    "cv = StratifiedShuffleSplit(n_splits=10, random_state=7)\n",
    "\n",
    "splits = [split_indices for split_indices in cv.split(features.values, targets.values)]\n",
    "\n",
    "# Calculate the training and testing confusion matrices with the classifier and \n",
    "train_df, test_df = confusion_score_model(\n",
    "    gridsearch_00.best_estimator_,\n",
    "    features,\n",
    "    targets,\n",
    "    cv_splits=splits, \n",
    ")\n",
    "\n",
    "train_df = fix_conf_mat_labels(train_df)\n",
    "test_df = fix_conf_mat_labels(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cache the confusion matrices.\n",
    "joblib.dump(\n",
    "    train_df,\n",
    "    data_save_dir+\"train_df_\"+modding_dirs[:-1]+\".pickle\", \n",
    ")\n",
    "joblib.dump(\n",
    "    test_df,\n",
    "    data_save_dir+\"test_df_\"+modding_dirs[:-1]+\".pickle\", \n",
    ")\n",
    "\n",
    "# save_kwargs(classer_init_kwargs, \"classer_init_kwargs\", data_save_dir)\n",
    "# save_kwargs(fitting_kwargs, \"fitting_kwargs\", data_save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the confusion matrices.\n",
    "fig, ax = plot_confusion_matrix(\n",
    "    train_df.divide(train_df[\"sum\"], axis=0),\n",
    "    title=\"Train CM\",\n",
    ")\n",
    "fig.savefig(plot_dir+\"train_df_\"+modding_dirs[:-1]+\".pdf\")\n",
    "\n",
    "fig, ax = plot_confusion_matrix(\n",
    "    test_df.divide(test_df[\"sum\"], axis=0),\n",
    "    title=\"Test CM\",\n",
    ")\n",
    "fig.savefig(plot_dir+\"test_df_\"+modding_dirs[:-1]+\".pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_idx_names = [\"\", \"spike\", \"noise\", \"sum\"]\n",
    "\n",
    "RF_cf = np.array(\n",
    "    [[9.76582046e-01, 1.86324424e-04, 3.98129112e-05, 0], \n",
    "     [4.92087582e-04, 1.74587578e-02, 0.00000000e+00, 0], \n",
    "     [3.39206003e-04, 1.59251645e-06, 4.90017311e-03, 0], \n",
    "    ]\n",
    ")\n",
    "\n",
    "RF_cf_df = pd.DataFrame(\n",
    "    data=RF_cf, \n",
    "    columns=col_idx_names, \n",
    "    index=[\"\", \"spike\", \"noise\",]\n",
    ")\n",
    "\n",
    "RF_cf_df.loc[:, \"sum\"] = RF_cf_df.sum(axis=0)\n",
    "# RF_cf_df.loc[\"sum\", :] = RF_cf.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the confusion matrices.\n",
    "fig, ax = plot_confusion_matrix(\n",
    "    RF_cf_df.divide(RF_cf_df[\"sum\"], axis=0),\n",
    "    title=\"RF test CM\",\n",
    ")\n",
    "fig.savefig(plot_dir+\"RF_test_df_\"+modding_dirs[:-1]+\".pdf\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
