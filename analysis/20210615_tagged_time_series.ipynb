{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Production of tagged time series for analysis\n",
    "\n",
    "The time series will be predicted upon by the trained classifier and then cached for future data viz and analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load up the requisite libraries and submodules.\n",
    "import copy\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import time\n",
    "import xgboost as xgb\n",
    "\n",
    "from datetime import datetime\n",
    "from dynomics import models\n",
    "from matplotlib.colors import LogNorm\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "# Define file locations.\n",
    "# DATA_DIR = \"../data/multiclass/\"\n",
    "DATA_SAVE_DIR = \"../data/20210615_labeled_timeseries/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load up the station IDs. Some of the Accl\n",
    "station_filenames_list = [\n",
    "    filename for filename in os.listdir(path=DATA_DIR)\n",
    "    if (filename[-7:]==\".pickle\") and (\"53155\" not in filename)\n",
    "]\n",
    "\n",
    "# List of \n",
    "stations_id_list = list(\n",
    "    set(\n",
    "        fname.split(\"_\")[2].split(\".\")[0] for fname in station_filenames_list\n",
    "    )\n",
    ")\n",
    "\n",
    "# Load features and targets into features and targets dictionaries, indexed\n",
    "# by station ID number.\n",
    "template_dict = {\n",
    "    station_id : None\n",
    "    for station_id in stations_id_list\n",
    "    if station_id != \"53155\"     # Station 53155's sensor data had data missing for at least one sensor\n",
    "                               # at literally every time point, so my data preprocessing eliminated it. \n",
    "}\n",
    "features_dict,targets_dict = copy.deepcopy(template_dict), copy.deepcopy(template_dict)\n",
    "del(template_dict)\n",
    "\n",
    "for fname in station_filenames_list:\n",
    "    station_id = fname.split(\"_\")[2].split(\".\")[0]\n",
    "    if station_id=='53155':\n",
    "        continue\n",
    "    elif \"features\" in fname:\n",
    "        features_dict[station_id] = pd.read_pickle(\n",
    "            DATA_DIR+fname,\n",
    "        )\n",
    "    elif \"targets\" in fname:\n",
    "        targets_dict[station_id] = pd.read_pickle(\n",
    "            DATA_DIR+fname,\n",
    "        )\n",
    "\n",
    "final_stations_list = [\n",
    "    station_id for station_id in features_dict.keys()\n",
    "]\n",
    "\n",
    "# Got the following station ID info from this URL:\n",
    "# https://mesonet.agron.iastate.edu/sites/site.php?station=23906&network=USCRN\n",
    "port_aransas_stat_id = \"23906\"\n",
    "feats_df_port_aransas = features_dict[port_aransas_stat_id]\n",
    "targs_df_port_aransas = targets_dict[port_aransas_stat_id]\n",
    "\n",
    "# Got the following date-exclusion idea from here:\n",
    "# https://stackoverflow.com/questions/55680603/pandas-filter-on-datetimeindex-by-excluding-date-range\n",
    "exclusion_dates = pd.date_range(start=\"2019-08-01\", end=\"2019-09-01\")\n",
    "\n",
    "features_dict[port_aransas_stat_id] = feats_df_port_aransas.loc[~feats_df_port_aransas.index.isin(exclusion_dates)]\n",
    "\n",
    "targets_dict[port_aransas_stat_id] = targs_df_port_aransas.loc[~targs_df_port_aransas.index.isin(exclusion_dates)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define ML functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_mkdirs(*paths):\n",
    "    for path in paths:\n",
    "        if not os.path.isdir(path):\n",
    "            os.makedirs(path)\n",
    "    return\n",
    "\n",
    "\n",
    "def fix_conf_mat_labels(conf_mat):\n",
    "    # Format metal names so as to remove the remnants of tuple-formatting,\n",
    "    # which is an artifact of the MySQL database and its concentration \n",
    "    # specifications.\n",
    "    new_confusion_matrix_labels = [\n",
    "        label.split(\"'\")[1] \n",
    "        if \"'\" in label else label\n",
    "        for label in conf_mat.index.values\n",
    "    ]\n",
    "    conf_mat.index = new_confusion_matrix_labels\n",
    "    conf_mat.columns = new_confusion_matrix_labels\n",
    "    return conf_mat\n",
    "\n",
    "\n",
    "def plot_confusion_matrix(\n",
    "        cm_df,\n",
    "        title=None,\n",
    "        cmap=plt.cm.Blues,\n",
    "        fontsize=12,\n",
    "        fontcolor=None,\n",
    "        num_round=4,\n",
    "        plot_top=0.88,\n",
    "        cbar_ticks=None,\n",
    "        cbar_min_divisor=2,\n",
    "        figsize=None\n",
    "):\n",
    "    \"\"\"\n",
    "    Create and return a matplotlib figure representing a confusion matrix.\n",
    "\n",
    "    Input:\n",
    "        cm_df : pandas.DataFrame\n",
    "            a pandas dataframe representing a confusion matrix\n",
    "        title : str\n",
    "            a plot title\n",
    "        cmap : color map\n",
    "            some pyplot colormap to use in plotting\n",
    "        fontsize : int\n",
    "            how large the text in each posititon of the matrix should be\n",
    "        fontcolor : str\n",
    "            the color that the text in each position of the matrix\n",
    "    Return: pyplot.figure\n",
    "        a figure object representing the plot\n",
    "\"\"\"\n",
    "\n",
    "    # Set figure title.\n",
    "    if title is None:\n",
    "        title = 'Confusion matrix'\n",
    "\n",
    "    # Set figure fontcolor.\n",
    "    if fontcolor is None:\n",
    "        fontcolor = \"black\"\n",
    "    \n",
    "    if figsize is None:\n",
    "        figsize = (14, 10)\n",
    "\n",
    "    conf_mat = cm_df.values\n",
    "    conf_mat_nozeros = cm_df.copy()\n",
    "    #     conf_mat_nozeros['Sum'] = 0\n",
    "    #     conf_mat_nozeros.loc['Sum'] = 0\n",
    "    conf_mat_nozeros = conf_mat_nozeros.values\n",
    "\n",
    "    # Get class names.\n",
    "    classes = cm_df.index\n",
    "\n",
    "    # Set color bar ticks and format their labels.\n",
    "    if cbar_ticks is None:\n",
    "        cbar_ticks = [0.001, 0.01, 0.1, 0.2, 0.4, 0.8, 1.0]\n",
    "    cbar_tick_labels = [str(label) for label in cbar_ticks]\n",
    "\n",
    "    # Set color bar minimum and maximum.\n",
    "    cbar_min = np.min(\n",
    "        [i for i in cm_df.values.ravel() if i > 0]) / cbar_min_divisor\n",
    "    cbar_max = np.max([i for i in cm_df.values.ravel() if i < 1])\n",
    "\n",
    "    # Eliminate actual zeros from plotting data.\n",
    "    for i, row in enumerate(conf_mat):\n",
    "        for j, col in enumerate(row):\n",
    "            if col < cbar_min:\n",
    "                conf_mat_nozeros[i, j] = cbar_min\n",
    "\n",
    "    # Initialize figure and axes objects and plot colored cells.\n",
    "    fig, ax = plt.subplots(\n",
    "        1,\n",
    "        1,\n",
    "        figsize=figsize\n",
    "    )\n",
    "    cax = ax.imshow(\n",
    "        conf_mat_nozeros,\n",
    "        interpolation='nearest',\n",
    "        cmap=cmap,\n",
    "        norm=LogNorm(vmin=cbar_min, vmax=cbar_max)\n",
    "    )\n",
    "\n",
    "    # Add color bar, figure title, labels, and axis ticks.\n",
    "    cbar = fig.colorbar(cax, ax=ax, ticks=cbar_ticks)\n",
    "    cbar.ax.set_yticklabels(cbar_tick_labels)\n",
    "    fig.suptitle(\n",
    "        title,\n",
    "        **{'x': 0.53, 'y': 0.97}\n",
    "    )\n",
    "    ax.set_ylabel('True label')\n",
    "    ax.set_xlabel('Predicted label')\n",
    "    ticks = list(range(len(classes)))\n",
    "    plt.xticks(ticks, classes, rotation=45)\n",
    "    plt.yticks(ticks, classes)\n",
    "    ax.tick_params(axis=u'both', which=u'both', length=0)\n",
    "\n",
    "    # Add numerical values to the matrix's cells.\n",
    "    for i in range(conf_mat.shape[0]):\n",
    "        for j in range(conf_mat.shape[1]):\n",
    "            ax.text(\n",
    "                j,\n",
    "                i,\n",
    "                # conf_mat[i, j],\n",
    "                '{results:.{digits}f}'.format(\n",
    "                    results=conf_mat[i, j],\n",
    "                    digits=num_round\n",
    "                    ),\n",
    "                horizontalalignment=\"center\",\n",
    "                color=fontcolor,\n",
    "                fontsize=fontsize\n",
    "            )\n",
    "\n",
    "    # Format final image for saving.\n",
    "    plt.tight_layout()\n",
    "    plt.subplots_adjust(top=plot_top)\n",
    "\n",
    "    return fig, ax\n",
    "\n",
    "\n",
    "# def save_kwargs(kwargs_dict, kwargs_dict_name, data_save_dir):\n",
    "#     with open(data_save_dir+kwargs_dict_name+\".txt\", \"w\") as output_file:\n",
    "#         output_file.write(json.dumps(kwargs_dict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concatenate anomaly data for ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_feats_dict = {\n",
    "    stat_id : None\n",
    "    for stat_id in final_stations_list\n",
    "    if features_dict[stat_id].shape[1]==15\n",
    "}\n",
    "for stat_id in final_stations_list:\n",
    "    \n",
    "    df_to_scale = copy.deepcopy(features_dict[stat_id]).drop(columns=[\"p_official\", \"t_official\"])\n",
    "    \n",
    "    if df_to_scale.shape[1]==15:\n",
    "#         df_to_scale[(df_to_scale == -99999)] = pd.NA\n",
    "#         df_to_scale = df_to_scale.interpolate(method=\"time\", axis=0)\n",
    "#         df_to_scale = df_to_scale.fillna(method=\"bfill\", axis=0)\n",
    "        scaler = StandardScaler(with_mean=True)\n",
    "        feats_scaled_array = scaler.fit_transform(df_to_scale)\n",
    "        feats_scaled_df = pd.DataFrame(data=feats_scaled_array, index=df_to_scale.index, columns=df_to_scale.columns)\n",
    "#         if np.isnan(feats_scaled_array).sum() == 0:\n",
    "        scaled_feats_dict[stat_id] = copy.deepcopy(feats_scaled_df)\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "final_station_ids_list = [stat_id for stat_id in scaled_feats_dict.keys()]        \n",
    "\n",
    "features_dfs_list = [scaled_feats_dict[station_id] for station_id in final_station_ids_list]\n",
    "targets_dfs_list = [targets_dict[station_id] for station_id in final_station_ids_list]\n",
    "\n",
    "scaled_feats_df = pd.concat(features_dfs_list, axis=0)\n",
    "targs_df = pd.concat(targets_dfs_list, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(627937, 16)\n"
     ]
    }
   ],
   "source": [
    "combined_scaledfeats_targs_df = pd.concat([scaled_feats_df,targs_df], axis=1)\n",
    "\n",
    "print(combined_scaledfeats_targs_df.shape)\n",
    "\n",
    "combined_scaledfeats_targs_NONAN_df = combined_scaledfeats_targs_df.dropna(how=\"any\", axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-isolate the targets and then combine them into a 1-D pd.series. \n",
    "# Whenever a row has at least one anomaly, then we will collapse that row's \n",
    "# values to a single value of 1. Rows with no anomalies shall be labeled as 0.\n",
    "ml_targs_df = combined_scaledfeats_targs_NONAN_df.iloc[:, 15]\n",
    "\n",
    "# Re-isolate the ML-ready features.\n",
    "ml_feats_df = combined_scaledfeats_targs_NONAN_df.iloc[:, :15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate the percentage of the ML-ready data that are anomalies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.32% of the data are anomalies.\n",
      "normal: 97.6808 %\n",
      "noise: 1.7951 %\n",
      "spike: 0.5241 %\n"
     ]
    }
   ],
   "source": [
    "percentage_anomalies = np.round(100 * (ml_targs_df != \"\").sum()/ml_targs_df.shape[0], 2 )\n",
    "\n",
    "print(f\"{percentage_anomalies}% of the data are anomalies.\")\n",
    "\n",
    "for label in ml_targs_df.unique():\n",
    "    num_labels = (ml_targs_df == label).sum()\n",
    "    if label==\"\":\n",
    "        label=\"normal\"\n",
    "    print(label+\":\", np.round(100*num_labels/ml_targs_df.shape[0],4),\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Various ML parameters, plus load the optimized classer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/ggraham/repos/innovates/analysis\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define caching directories.\n",
    "master_dir = \"20210615_generate_tagged_time_series/\"\n",
    "plot_dir = \"../plots/\" + master_dir\n",
    "data_save_dir = \"../data/\" + master_dir\n",
    "check_mkdirs(plot_dir, data_save_dir)\n",
    "\n",
    "classer_init_kwargs = {\n",
    "    \"n_jobs\":-1,\n",
    "    \"objective\":\"multi:softmax\",\n",
    "}\n",
    "\n",
    "fitting_kwargs = {\n",
    "#     \"early_stopping_rounds\":50,\n",
    "    \"eval_metric\":\"merror\",\n",
    "    \"verbose\":False,\n",
    "}\n",
    "\n",
    "param_test_00 = {\n",
    "    \"n_estimators\": [int(np.round(n, 0)) for n in np.geomspace(20, 1000, num=6)], \n",
    "    \"learning_rate\":[0.1, 0.4, 0.8],\n",
    "    'max_depth':range(7, 16,2),\n",
    "    'min_child_weight':range(5, 13, 2),\n",
    "    'gamma':[i/10.0 for i in range(0, 6)]\n",
    "}\n",
    "\n",
    "features = combined_scaledfeats_targs_NONAN_df.iloc[:,0:15]\n",
    "\n",
    "targets = combined_scaledfeats_targs_NONAN_df[\"TAGS\"].to_frame()\n",
    "\n",
    "# ML RANDOMIZED SEARCH WAS PERFORMED AT THIS STEP.\n",
    "# I erased the dang thing, though, so I wouldn't accidentally re-train the classer.\n",
    "\n",
    "gridsearch_00 = joblib.load(\"../data/20210506_XGB_MC_random_search/gridsearch_00.pickle\")\n",
    "\n",
    "print(gridsearch_00.best_params_)\n",
    "\n",
    "print(gridsearch_00.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate confusion matrices using best estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv = StratifiedShuffleSplit(n_splits=10, random_state=7)\n",
    "# cv_splits = [split_indices for split_indices in cv.split(features.values, targets.values)]\n",
    "\n",
    "# feature_frame = features\n",
    "# target_frame = targets\n",
    "# classer = gridsearch_00.best_estimator_\n",
    "\n",
    "# # Create variables to store conf matrix values during cross validation\n",
    "# unique_labels = target_frame.iloc[:, 0].unique()\n",
    "# num_labels = len(unique_labels)\n",
    "# test_mat = np.zeros((num_labels, num_labels))\n",
    "# train_mat = np.zeros((num_labels, num_labels))\n",
    "# # perform cross validation\n",
    "# for split_idx, (train, test) in enumerate(cv_splits[:1]):\n",
    "#     print(\"##################################################\")\n",
    "#     print(\"         ###### Processing \"+str(split_idx+1)+\" of \"+str(len(cv_splits))+\" ######\")\n",
    "#     print(\"            \" + time.ctime())\n",
    "#     print(\"##################################################\")\n",
    "#     # get train and test splits\n",
    "#     train_X = feature_frame.values[train]\n",
    "#     train_y = target_frame.values.ravel()[train]\n",
    "#     test_X = feature_frame.values[test]\n",
    "#     test_y = target_frame.values.ravel()[test]\n",
    "\n",
    "#     # fit training data\n",
    "#     classer.fit(\n",
    "#         train_X, train_y, \n",
    "#         eval_set=[(test_X, test_y)], \n",
    "#         verbose=False,\n",
    "#     )\n",
    "\n",
    "#     # Predict for training data and update confusion matrix\n",
    "#     train_p = classer.predict(train_X)\n",
    "#     test_p = classer.predict(test_X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data/20210615_labeled_timeseries/test/test_p.pickle']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Cache these dirs for testing.\n",
    "\n",
    "# check_mkdirs(data_save_dir+\"test/\")\n",
    "\n",
    "# joblib.dump(train_p, data_save_dir+\"test/train_p.pickle\")\n",
    "# joblib.dump(test_p, data_save_dir+\"test/test_p.pickle\")\n",
    "# joblib.dump(cv_splits, data_save_dir+\"test/cv_splits.pickle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stitch predicted points back to their original time series locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['', '', '', ..., '', '', ''], dtype=object)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(array([492972, 302149, 183822, ..., 502872, 552569,  55121]),\n",
       "  array([443968,  39708,  95277, ...,   3572,  95457, 282265])),\n",
       " (array([285804,  88694,  15516, ..., 334268, 404635, 166587]),\n",
       "  array([289066, 254933, 575210, ...,  60203, 513035,  35766])),\n",
       " (array([283116, 477960, 298293, ..., 597419, 148152, 385399]),\n",
       "  array([477174, 620332, 466580, ..., 485094, 498651,  15531])),\n",
       " (array([464725, 331141, 205850, ...,  24605,  55490, 166796]),\n",
       "  array([598401, 258567, 583063, ..., 386132, 587560, 308606])),\n",
       " (array([592595, 372768, 455708, ..., 220128, 163736, 294188]),\n",
       "  array([602731, 549166,  44363, ...,  88800,  31495, 490300])),\n",
       " (array([ 57005, 312065, 207233, ..., 599628, 514811,  50218]),\n",
       "  array([ 16559, 168525, 210891, ...,  89114, 128799, 310693])),\n",
       " (array([446412, 441495, 414131, ...,   7463, 515073, 216067]),\n",
       "  array([249419, 377915, 353784, ..., 515345, 159413, 120673])),\n",
       " (array([142181, 408212, 540835, ..., 474145, 208040, 132648]),\n",
       "  array([519113, 191134, 170031, ..., 594393, 612775, 353086])),\n",
       " (array([138639, 560003, 305296, ..., 315617, 369528,  27514]),\n",
       "  array([268673, 401912, 262887, ..., 494943,  86346, 193498])),\n",
       " (array([619532, 395000, 192333, ..., 453679, 382565, 472805]),\n",
       "  array([511760, 467443, 119305, ..., 153363, 120513, 243439]))]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cv_splits splits on combined_scaledfeats_targs_NONAN_df.\n",
    "# combined_scaledfeats_targs_NONAN_df was created by stitching together\n",
    "# features_dfs_list = [scaled_feats_dict[station_id] for station_id in final_station_ids_list]\n",
    "# and then converting it into \n",
    "# scaled_feats_df = pd.concat(features_dfs_list, axis=0)\n",
    "# and then again into \n",
    "# combined_scaledfeats_targs_df = pd.concat([scaled_feats_df,targs_df], axis=1).\n",
    "# Phew. That's a lot of hoops. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "627937\n"
     ]
    }
   ],
   "source": [
    "# total_length = 0\n",
    "# for station_id in final_station_ids_list:\n",
    "#     total_length+=scaled_feats_dict[station_id].shape[0]\n",
    "\n",
    "multiindex_outer = list(station_id for station_id in final_station_ids_list for _ in range(scaled_feats_dict[station_id].shape[0]))\n",
    "\n",
    "print(len(multiindex_outer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create multiindex arrays.\n",
    "mi_arrays = [\n",
    "    np.array(multiindex_outer),\n",
    "    scaled_feats_df.index.values\n",
    "]\n",
    "\n",
    "# Get the original time series data, along with precip and temp.\n",
    "# This DF's values and columns will be used to create a new multi-index dataframe in the next line.\n",
    "features_df = pd.concat([features_dict[station_id] for station_id in final_station_ids_list])\n",
    "\n",
    "# Create a new multiindex dataframe with the station ID #'s. \n",
    "mi_features_df = pd.DataFrame(\n",
    "    data=features_df.values, \n",
    "    columns=features_df.columns, \n",
    "    index=mi_arrays\n",
    ")\n",
    "\n",
    "# Add a column for true labels and another for predicted labels.\n",
    "mi_features_df[\"true_labels\"] = targs_df.values\n",
    "\n",
    "# Sanity-check that no additional labels were created.\n",
    "print(set(mi_features_df.true_labels.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(627937, 18)"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mi_features_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load predicted labels into CV splits-indexed locations in separate dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an empty DF into which I'll load the predicted labels.\n",
    "# They will have to be loaded in using the CV splits. \n",
    "predicted_labels_df = pd.DataFrame(columns=[\"predicted_labels\"], index=mi_features_df.index,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "565143\n",
      "62794\n",
      "62794\n"
     ]
    }
   ],
   "source": [
    "# Sanity check all the lengths of the CV splits arrays.\n",
    "print(len(cv_splits[0][0]))\n",
    "\n",
    "print(len(cv_splits[0][1]))\n",
    "\n",
    "print(len(test_p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape the dang predicted labels.\n",
    "test_p_reshaped = [[label] for label in test_p]\n",
    "\n",
    "# Load the reshaped labels into their appropriate indices within the predicted labels.\n",
    "predicted_labels_df.iloc[cv_splits[0][1]] = test_p_reshaped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# Compare the indices of the loaded predicted labels wiht the original cv_splits indices.\n",
    "idx_locs = [idx for idx, boolean in enumerate(predicted_labels_df.notna().values.ravel()) if boolean]\n",
    "\n",
    "cv_splits[0][1].sort()\n",
    "\n",
    "cv_splits_array = cv_splits[0][1]\n",
    "\n",
    "print(np.array_equal(idx_locs, cv_splits_array))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load up the remaining predictions and add them to the master dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_dict = {\n",
    "    split_idx : joblib.load(\n",
    "        \"../data/20210615_labeled_timeseries/test_p\"+str(split_idx).zfill(2)+\".pickle\"\n",
    "    )\n",
    "    for split_idx, split in enumerate(cv_splits)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-initialize an empty DF into which I'll load the predicted labels.\n",
    "# They will have to be loaded in using the CV splits. \n",
    "predicted_labels_df = pd.DataFrame(columns=[\"predicted_labels\"], index=mi_features_df.index,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(62794,)"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "for split_idx, split in enumerate(cv_splits):\n",
    "    \n",
    "    predictions = predictions_dict[split_idx]\n",
    "    \n",
    "    # Reshape the dang predicted labels.\n",
    "    predictions_reshaped = [[label] for label in predictions]\n",
    "\n",
    "    # Load the reshaped labels into their appropriate indices within the predicted labels.\n",
    "    predicted_labels_df.iloc[split[1]] = predictions_reshaped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "for split_pair in cv_splits:\n",
    "    split_pair[0].sort()\n",
    "    split_pair[1].sort()\n",
    "    \n",
    "all_splits_list = [\n",
    "    split[0] for split in cv_splits\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([     0,      1,      2, ..., 627934, 627935, 627936]),\n",
       " array([     0,      1,      2, ..., 627933, 627935, 627936]),\n",
       " array([     0,      2,      3, ..., 627934, 627935, 627936]),\n",
       " array([     0,      1,      2, ..., 627934, 627935, 627936]),\n",
       " array([     0,      1,      2, ..., 627934, 627935, 627936]),\n",
       " array([     0,      1,      2, ..., 627934, 627935, 627936]),\n",
       " array([     0,      1,      2, ..., 627934, 627935, 627936]),\n",
       " array([     0,      2,      3, ..., 627933, 627934, 627936]),\n",
       " array([     0,      2,      3, ..., 627934, 627935, 627936]),\n",
       " array([     0,      1,      3, ..., 627934, 627935, 627936])]"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_splits_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_splits_array = np.concatenate(all_splits_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_splits_array.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(627940,)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_splits_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "218585"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_labels_df.isna().values.ravel().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_labels_df_NONA = predicted_labels_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "mi_features_df_NONA = mi_features_df.loc[predicted_labels_df_NONA.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mi_all_df = pd.concat([mi_features_df_NONA, predicted_labels_df_NONA], axis=1)\n",
    "\n",
    "# joblib.dump(mi_all_df, \"../data/20210615_labeled_timeseries/multiindexed_features_truepredicted_labels.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "407860\n",
      "409352\n",
      "0.9963552150716254\n"
     ]
    }
   ],
   "source": [
    "print((mi_all_df.true_labels.values == mi_all_df.predicted_labels.values).sum())\n",
    "\n",
    "print(mi_all_df.shape[0])\n",
    "\n",
    "print(\n",
    "    (mi_all_df.true_labels.values == mi_all_df.predicted_labels.values).sum() / mi_all_df.shape[0]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore mi_all_df, which is the multi-indexed pandas.DataFrame containing all raw features, true labels, and predicted labels with the time stamps and station IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "mi_all_df_copy = mi_all_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mi_all_df_copy.index.set_names(\"station_id\", level=0, inplace=True)\n",
    "# mi_all_df_copy.index.set_names(\"time\", level=1, inplace=True)\n",
    "mi_all_df.index.set_names(\"station_id\", level=0, inplace=True)\n",
    "mi_all_df.index.set_names(\"time\", level=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert all temps to float64.\n",
    "mi_all_df[\"t_official\"] = pd.to_numeric(mi_all_df[\"t_official\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert all precip to float64.\n",
    "mi_all_df[\"p_official\"] = pd.to_numeric(mi_all_df[\"p_official\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>p_official</th>\n",
       "      <th>sw1005</th>\n",
       "      <th>sw1010</th>\n",
       "      <th>sw1020</th>\n",
       "      <th>sw1050</th>\n",
       "      <th>sw1100</th>\n",
       "      <th>sw2005</th>\n",
       "      <th>sw2010</th>\n",
       "      <th>sw2020</th>\n",
       "      <th>sw2050</th>\n",
       "      <th>sw2100</th>\n",
       "      <th>sw3005</th>\n",
       "      <th>sw3010</th>\n",
       "      <th>sw3020</th>\n",
       "      <th>sw3050</th>\n",
       "      <th>sw3100</th>\n",
       "      <th>t_official</th>\n",
       "      <th>true_labels</th>\n",
       "      <th>predicted_labels</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>station_id</th>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"11\" valign=\"top\">53968</th>\n",
       "      <th>2019-12-12 00:00:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.191</td>\n",
       "      <td>0.256</td>\n",
       "      <td>0.309</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.235</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.128</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.179</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-12 01:00:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.191</td>\n",
       "      <td>0.256</td>\n",
       "      <td>0.309</td>\n",
       "      <td>0.276</td>\n",
       "      <td>0.235</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.127</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.196</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-12 02:00:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.256</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.276</td>\n",
       "      <td>0.235</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.126</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.748</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-12 03:00:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.256</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.276</td>\n",
       "      <td>0.236</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.126</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.666</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-12 05:00:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.256</td>\n",
       "      <td>0.309</td>\n",
       "      <td>0.276</td>\n",
       "      <td>0.236</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.126</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.948</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-06-29 08:00:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.144</td>\n",
       "      <td>0.195</td>\n",
       "      <td>0.264</td>\n",
       "      <td>0.305</td>\n",
       "      <td>0.324</td>\n",
       "      <td>0.113</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.344</td>\n",
       "      <td>1.286</td>\n",
       "      <td>0.205</td>\n",
       "      <td>0</td>\n",
       "      <td>0.351</td>\n",
       "      <td>26.326</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-06-29 13:00:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.144</td>\n",
       "      <td>0.194</td>\n",
       "      <td>0.264</td>\n",
       "      <td>0.305</td>\n",
       "      <td>0.323</td>\n",
       "      <td>0.113</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.986</td>\n",
       "      <td>0.827</td>\n",
       "      <td>0.205</td>\n",
       "      <td>0</td>\n",
       "      <td>0.351</td>\n",
       "      <td>27.092</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-06-29 14:00:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.144</td>\n",
       "      <td>0.194</td>\n",
       "      <td>0.264</td>\n",
       "      <td>0.305</td>\n",
       "      <td>0.323</td>\n",
       "      <td>0.114</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.244</td>\n",
       "      <td>0.936</td>\n",
       "      <td>0.204</td>\n",
       "      <td>0</td>\n",
       "      <td>0.351</td>\n",
       "      <td>28.087</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-06-29 15:00:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.194</td>\n",
       "      <td>0.263</td>\n",
       "      <td>0.304</td>\n",
       "      <td>0.322</td>\n",
       "      <td>0.114</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.638</td>\n",
       "      <td>1.127</td>\n",
       "      <td>0.205</td>\n",
       "      <td>0</td>\n",
       "      <td>0.35</td>\n",
       "      <td>28.904</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-06-29 19:00:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.141</td>\n",
       "      <td>0.192</td>\n",
       "      <td>0.258</td>\n",
       "      <td>0.303</td>\n",
       "      <td>0.321</td>\n",
       "      <td>0.112</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.011</td>\n",
       "      <td>2.719</td>\n",
       "      <td>0.204</td>\n",
       "      <td>0</td>\n",
       "      <td>0.349</td>\n",
       "      <td>31.370</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3138 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                p_official sw1005 sw1010 sw1020 sw1050 sw1100  \\\n",
       "station_id time                                                                 \n",
       "53968      2019-12-12 00:00:00         0.0  0.191  0.256  0.309   0.28  0.235   \n",
       "           2019-12-12 01:00:00         0.0  0.191  0.256  0.309  0.276  0.235   \n",
       "           2019-12-12 02:00:00         0.0   0.19  0.256   0.31  0.276  0.235   \n",
       "           2019-12-12 03:00:00         0.0   0.19  0.256   0.31  0.276  0.236   \n",
       "           2019-12-12 05:00:00         0.0   0.19  0.256  0.309  0.276  0.236   \n",
       "...                                    ...    ...    ...    ...    ...    ...   \n",
       "           2020-06-29 08:00:00         0.0  0.144  0.195  0.264  0.305  0.324   \n",
       "           2020-06-29 13:00:00         0.0  0.144  0.194  0.264  0.305  0.323   \n",
       "           2020-06-29 14:00:00         0.0  0.144  0.194  0.264  0.305  0.323   \n",
       "           2020-06-29 15:00:00         0.0  0.143  0.194  0.263  0.304  0.322   \n",
       "           2020-06-29 19:00:00         0.0  0.141  0.192  0.258  0.303  0.321   \n",
       "\n",
       "                               sw2005 sw2010 sw2020 sw2050 sw2100 sw3005  \\\n",
       "station_id time                                                            \n",
       "53968      2019-12-12 00:00:00      0      0      0      0      0      0   \n",
       "           2019-12-12 01:00:00      0      0      0      0      0      0   \n",
       "           2019-12-12 02:00:00      0      0      0      0      0      0   \n",
       "           2019-12-12 03:00:00      0      0      0      0      0      0   \n",
       "           2019-12-12 05:00:00      0      0      0      0      0      0   \n",
       "...                               ...    ...    ...    ...    ...    ...   \n",
       "           2020-06-29 08:00:00  0.113      0      0      0      0  1.344   \n",
       "           2020-06-29 13:00:00  0.113      0      0      0      0  0.986   \n",
       "           2020-06-29 14:00:00  0.114      0      0      0      0  1.244   \n",
       "           2020-06-29 15:00:00  0.114      0      0      0      0  1.638   \n",
       "           2020-06-29 19:00:00  0.112      0      0      0      0  4.011   \n",
       "\n",
       "                               sw3010 sw3020 sw3050 sw3100  t_official  \\\n",
       "station_id time                                                          \n",
       "53968      2019-12-12 00:00:00      0  0.128      0      0       7.179   \n",
       "           2019-12-12 01:00:00      0  0.127      0      0       5.196   \n",
       "           2019-12-12 02:00:00      0  0.126      0      0       5.748   \n",
       "           2019-12-12 03:00:00      0  0.126      0      0       5.666   \n",
       "           2019-12-12 05:00:00      0  0.126      0      0       4.948   \n",
       "...                               ...    ...    ...    ...         ...   \n",
       "           2020-06-29 08:00:00  1.286  0.205      0  0.351      26.326   \n",
       "           2020-06-29 13:00:00  0.827  0.205      0  0.351      27.092   \n",
       "           2020-06-29 14:00:00  0.936  0.204      0  0.351      28.087   \n",
       "           2020-06-29 15:00:00  1.127  0.205      0   0.35      28.904   \n",
       "           2020-06-29 19:00:00  2.719  0.204      0  0.349      31.370   \n",
       "\n",
       "                               true_labels predicted_labels  \n",
       "station_id time                                              \n",
       "53968      2019-12-12 00:00:00                               \n",
       "           2019-12-12 01:00:00                               \n",
       "           2019-12-12 02:00:00                               \n",
       "           2019-12-12 03:00:00                               \n",
       "           2019-12-12 05:00:00                               \n",
       "...                                    ...              ...  \n",
       "           2020-06-29 08:00:00                               \n",
       "           2020-06-29 13:00:00                               \n",
       "           2020-06-29 14:00:00                               \n",
       "           2020-06-29 15:00:00                               \n",
       "           2020-06-29 19:00:00                               \n",
       "\n",
       "[3138 rows x 19 columns]"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mi_all_df.loc[mi_all_df.index.get_level_values(\"station_id\")==\"53968\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "station_df = mi_all_df.loc[mi_all_df.index.get_level_values(\"station_id\")==\"53968\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1a9a04430>]"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the temps to make sure they look sane.\n",
    "# plt.plot(station_df[\"t_official\"].values)\n",
    "# sns.lineplot(x=\"time\", y=\"t_official\", data=station_df)\n",
    "plt.plot(station_df[\"sw1005\"].values[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['7.179', '5.196', '5.748', ..., '28.087', '28.904', '31.37'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "station_df[\"t_official\"].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Output these values in CSV form for Ronnie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_save_dir = DATA_SAVE_DIR+\"csv_station/\"\n",
    "check_mkdirs(csv_save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "station_df.to_csv(csv_save_dir+\"save_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "for station_id in final_station_ids_list:\n",
    "    station_df = mi_all_df.loc[mi_all_df.index.get_level_values(\"station_id\")==station_id]\n",
    "    station_df.to_csv(csv_save_dir+\"station_\"+station_id+\"_data_labels.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Go back over and inspect results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[399168,    536,    134],\n",
       "       [   570,   6785,      2],\n",
       "       [   246,      4,   1907]])"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models.confusion_matrix(mi_all_df.true_labels.values, mi_all_df.predicted_labels.values, labels = [\"\", \"noise\", \"spike\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2157"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(mi_all_df.true_labels == \"spike\").sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m\n",
       "\u001b[0mplot_confusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mcm_df\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mtitle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m<\u001b[0m\u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinearSegmentedColormap\u001b[0m \u001b[0mobject\u001b[0m \u001b[0mat\u001b[0m \u001b[0;36m0x1180aca60\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mfontsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mfontcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mnum_round\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mplot_top\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.88\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mcbar_ticks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mcbar_min_divisor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "Create and return a matplotlib figure representing a confusion matrix.\n",
       "\n",
       "Input:\n",
       "    cm_df : pandas.DataFrame\n",
       "        a pandas dataframe representing a confusion matrix\n",
       "    title : str\n",
       "        a plot title\n",
       "    cmap : color map\n",
       "        some pyplot colormap to use in plotting\n",
       "    fontsize : int\n",
       "        how large the text in each posititon of the matrix should be\n",
       "    fontcolor : str\n",
       "        the color that the text in each position of the matrix\n",
       "Return: pyplot.figure\n",
       "    a figure object representing the plot\n",
       "\u001b[0;31mFile:\u001b[0m      ~/repos/innovates/analysis/<ipython-input-3-53e6e71ceed0>\n",
       "\u001b[0;31mType:\u001b[0m      function\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrix(confusion_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "`\n",
    "\n",
    "a\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "a\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
